---
title: "CEWL Data Wrangling"
author: "Savannah Weaver"
date: "2021"
output: pdf_document
toc: TRUE
---


# Packages

```{r setup, include = TRUE, message = FALSE}
if (!require("tidyverse")) install.packages("tidyverse")
library("tidyverse") # workflow and plots
```


# Background and Goals

In this R script, I bring all the data files for CEWL (cutaneous evaporative water loss) into one dataframe, check the distribution of replicates, omit outliers, and average remaining replicates. The final values will be more precise and accurate estimates of the true CEWL.


# Load Data

1. Compile a list of the filenames I need to read-in.

```{r filenames}
# make a list of file names of all data to load in
filenames <- list.files(path = "data/CEWL", pattern = "\\.csv$")
```

2. Make a function that will read in the data from each csv, name and organize the data correctly. 

```{r function to load data}
read_CEWL_file <- function(filename) {
  
  dat <- read.csv(file.path("data/CEWL", filename), # load file
                header = TRUE # each csv has headers
                ) %>%
    # select only the relevant values
    dplyr::select(date = Date, 
                  time = Time, 
                  status = Status,
                  ID_rep_no = Comments,
                  CEWL_g_m2h = 'TEWL..g..m2h..', 
                  msmt_temp_C = 'AmbT..C.', 
                  msmt_RH_percent = 'AmbRH....'
                  ) %>%
    # extract individual_ID and replicate number
    dplyr::mutate(ID_rep_no = as.character(ID_rep_no),
                  individual_ID = as.numeric(substr(ID_rep_no, 1, 3)),
                  replicate_no = as.numeric(substr(ID_rep_no, 5, 5))
                  )
  
  # return the dataframe for that single csv file
  dat
}
```

3. Apply the function I made to all of the filenames I compiled, then put all of those dataframes into one dataframe. This will print warnings saying that header and col.names are different lengths, because the data has extra notes cols that we read-in, but get rid of.
&
4. Filter out failed measurements and properly format data classes.

```{r load and filter CEWL data}
# apply function to get data from all csvs
all_CEWL_data <- lapply(filenames, read_CEWL_file) %>%
  # paste all data files together into one df by row
  reduce(rbind) %>%
  # only use completed measurements
  dplyr::filter(status == "Normal") %>%
  # properly format data classes
  mutate(date_time = as.POSIXct(paste(date, time), 
                                format = "%m/%d/%y %I:%M:%S %p"),
         date = as.Date(date, 
                        format = "%m/%d/%y"),
         time = as.POSIXct(time, 
                           format = "%I:%M:%S %p"),
         status = as.factor(status),
         individual_ID = as.factor(individual_ID),
         #replicate_no = as.factor(replicate_no)
         # don't make replicate a factor
         # that way I can easily add new levels later
         )
summary(all_CEWL_data)
```





# Replicates

## Assess Variation

We want the Coefficient of Variation (CV) among our technical replicates to be small. We need to calculate it to identify whether there may be outliers.

```{r asses variation}
CVs <- all_CEWL_data %>%
  group_by(individual_ID, date) %>%
  summarise(mean = mean(CEWL_g_m2h),
            SD = sd(CEWL_g_m2h),
            CV = (SD/mean) *100,
            min = min(CEWL_g_m2h),
            max = max(CEWL_g_m2h),
            CEWL_range = max - min
            )
summary(CVs)
hist(CVs$CV)
hist(CVs$CEWL_range) 
```

We expect CV for technical replicates to be < 10-15%, so we must determine whether the CVs > 15% are due to outlier replicates.



## Find Outliers Quantitatively

```{r}
outliers_found <- all_CEWL_data %>%
  group_by(individual_ID, date) %>%
  summarise(outs = boxplot.stats(CEWL_g_m2h)$out) %>%
  mutate(outlier = "Yes")
```

Based on the plots, the list of outliers I compiled is correct.


## Remove Outliers

To remove the outliers, I can join the outlier data to the full data, look for any matches, then delete those outliers I find.

```{r}
outliers_omitted <- all_CEWL_data %>%
  left_join(outliers_found, by = c('individual_ID', 'date', 
                                    'CEWL_g_m2h' = 'outs')) %>%
  mutate(outlier = as.factor(case_when(outlier == "Yes" ~ "Yes",
                             is.na(outlier) == TRUE ~ "No"))) %>%
  dplyr::filter(!(outlier == "Yes"))
```




## Re-Assess Variation

```{r re-check variation}
new_CVs <- outliers_omitted %>%
  group_by(individual_ID, date) %>%
  summarise(mean = mean(CEWL_g_m2h),
            SD = sd(CEWL_g_m2h),
            CV = (SD/mean) *100,
            min = min(CEWL_g_m2h),
            max = max(CEWL_g_m2h),
            CEWL_range = max - min)
summary(new_CVs)
hist(new_CVs$CV)
hist(CVs$CV)
hist(new_CVs$CEWL_range) 
hist(CVs$CEWL_range) 
```


Unfortunately, CVs are still skewed to the right, but overall, CVs are much lower and are mostly < 5-10%. 

We should just check the few technical replicate sets with new_CV still >25.

```{r}
new_CVs %>% dplyr::filter(CV>25)
outliers_omitted %>% dplyr::filter(individual_ID %in% c(206, 224, 235, 271, 291))
```

The values are pretty well-distributed across the wide ranges for those rep sets, so even though pretty messy, we have to continue as-is.

## Average Replicates (outliers removed) & Join Cloacal Temp Data

```{r get replicate means}
CEWL_final <- outliers_omitted %>%
  group_by(date, individual_ID) %>%
  summarise(CEWL_g_m2h_mean = mean(CEWL_g_m2h),
            msmt_temp_C = mean(msmt_temp_C),
            msmt_RH_percent = mean(msmt_RH_percent)) %>%
  dplyr::filter(complete.cases(CEWL_g_m2h_mean))
head(CEWL_final)
```


# Export

Save the cleaned data for models and figures.

```{r save clean data}
write_rds(CEWL_final, "./data/CEWL_dat_all_clean.RDS")
```



